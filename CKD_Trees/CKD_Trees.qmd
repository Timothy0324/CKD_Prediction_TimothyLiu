---
title: "Assignment 04 – Trees (CKD)"
author: "Timothy Liu"
format: pdf
editor: visual
---

**Dataset & link.** This report analyzes the **UCI Chronic Kidney Disease** dataset (≈400 patients, 24 variables) containing demographics, labs, and conditions relevant to CKD. Source: <https://archive.ics.uci.edu/dataset/336/chronic+kidney+disease>

# Executive Summary

1.  The purpose of my analysis is to understand the key factors that influence the presence of **Chronic Kidney Disease (CKD)** and the variation in **hemoglobin levels** among patients. The categorical dependent variable for the classification models is **CKD class (1 = CKD, 0 = Not CKD)**, while the continuous dependent variable for the regression model is **hemoglobin**. The dataset used for this analysis is the **Chronic Kidney Disease dataset from the UCI Machine Learning Repository**, which contains clinical and laboratory information on 400 patients.

2.  The data preparation was completed in previous assignments. All numeric variables were converted to appropriate numeric types, and categorical variables such as hypertension, diabetes, and CKD status were properly factorized. Missing values were imputed using the **median for numeric** and **mode for categorical variables**, ensuring a complete and consistent dataset for tree modeling.

3.  Three decision trees were developed for this assignment:

    **Tree A (Classification Tree)** predicting CKD using **age, blood pressure, serum creatinine, and hemoglobin**.

    **Tree B (Classification Tree)** predicting CKD using **hypertension, diabetes, coronary artery disease, and anemia**.

    **Tree C (Regression Tree)** predicting **hemoglobin** based on **age, blood pressure, hypertension, and CKD class**.

4.  Among the three trees, **Tree A** was selected as the best-performing model. It achieved an **accuracy of 92.5%**, **sensitivity of 90.7%**, **specificity of 96.1%**, and a **Kappa of 0.84**, demonstrating excellent predictive performance and strong agreement with actual CKD classifications. While Tree B was slightly simpler, it performed worse (accuracy = 81.3%) and missed more CKD cases (sensitivity = 72.2%). Tree C (the regression tree) achieved an **RMSE of 1.88** and **MAE of 1.44**, indicating moderate precision in predicting hemoglobin levels.

5.  The best tree (Tree A) was compared to the **Logistic Regression Model 1** developed previously, which used the same predictors: **age, blood pressure, serum creatinine, and hemoglobin**. The logistic model achieved a **pseudo-R² of 0.77** and **ROC-AUC of 0.98**, confirming a strong model fit. Both models identified **serum creatinine and hemoglobin** as the most influential predictors of CKD, showing consistency in clinical interpretation. While the logistic regression provided higher statistical precision, the classification tree offered better visual interpretability and decision threshold transparency. Therefore, **Tree A is selected as the final model** due to its high accuracy, balanced performance, and intuitive interpretability.

6.  The final model selected for this analysis is the **Classification Tree A**, which best balances predictive performance, interpretability, and clinical relevance. The tree demonstrates that **serum creatinine** and **hemoglobin** are the two most important variables for identifying CKD cases. Specifically, patients with **higher serum creatinine** and **lower hemoglobin** levels have a substantially greater likelihood of CKD, which aligns closely with medical understanding of kidney dysfunction. The model achieved **92.5 % accuracy**, **90.7 % sensitivity**, and **96.1 % specificity**, confirming that it can accurately distinguish CKD from non-CKD patients. While the logistic regression model achieved slightly higher statistical measures (AUC = 0.98, pseudo-R² = 0.77), the classification tree provides clearer, rule-based insights that can be easily interpreted by clinicians and stakeholders. Overall, the CART model effectively captures the key drivers of CKD and offers a transparent framework for clinical decision-making and early risk identification.

```{r}
library(dplyr)
library(ggplot2)
library(forcats)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
```

```{r}
ckd_raw <- read.csv("chronic_kidney_disease.csv",
                    na.strings = c("?", "", "NA"))

glimpse(ckd_raw)
summary(ckd_raw)

```

```{r}
# define column names (26 expected + 1 "extra")
col_names <- c("id","age","bp","sg","al","su","rbc","pc","pcc","ba","bgr","bu",
               "sc","sod","pot","hemo","pcv","wbcc","rbcc","htn","dm","cad",
               "appet","pe","ane","class","extra")

ckd_raw <- read.csv("chronic_kidney_disease.csv",
                    header = TRUE, na.strings = c("?", "", "NA"),
                    col.names = col_names, fill = TRUE)

# drop the "extra" column
ckd_raw <- ckd_raw %>% select(-extra)

glimpse(ckd_raw)
```

```{r}
# numeric variables
num_cols <- c("age","bp","sg","al","su","bgr","bu","sc",
              "sod","pot","hemo","pcv","wbcc","rbcc")

ckd1 <- ckd_raw %>%
  mutate(across(all_of(num_cols), ~as.numeric(.))) %>%
  mutate(
    rbc   = factor(rbc, levels = c("normal","abnormal")),
    pc    = factor(pc, levels = c("normal","abnormal")),
    pcc   = factor(pcc, levels = c("notpresent","present")),
    ba    = factor(ba,  levels = c("notpresent","present")),
    htn   = factor(htn, levels = c("no","yes")),
    dm    = factor(dm,  levels = c("no","yes")),
    cad   = factor(cad, levels = c("no","yes")),
    appet = factor(appet, levels = c("poor","good")),
    pe    = factor(pe,   levels = c("no","yes")),
    ane   = factor(ane,  levels = c("no","yes")),
    class = factor(class, levels = c("notckd","ckd"))
  )

```

```{r}
colSums(is.na(ckd1))
```

-   I converted numeric-like columns to numeric and standardized categorical columns to consistent factor levels (yes/no, present/notpresent, normal/abnormal, class = notckd/ckd).

-   And then I counted remaining NAs with `colSums(is.na(ckd1))`.

```{r}
# Helper function for categorical mode
Mode <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

```{r}
# Define numeric and categorical columns
num_cols <- c("age","bp","sg","al","su","bgr","bu","sc",
              "sod","pot","hemo","pcv","wbcc","rbcc")

cat_cols <- c("rbc","pc","pcc","ba","htn","dm","cad",
              "appet","pe","ane","class")
```

```{r}
# Impute missing values
ckd_clean <- ckd1 %>%
  # Numeric → median imputation
  mutate(across(all_of(num_cols),
                ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
  # Categorical → mode imputation
  mutate(across(all_of(cat_cols),
                ~ ifelse(is.na(.), Mode(.), .))) %>%
  # Make sure categorical vars are factors again
  mutate(across(all_of(cat_cols), ~ factor(.)))
```

```{r}
colSums(is.na(ckd_clean))
```

```{r}
ckd_clean <- ckd_clean %>%
  mutate(class = recode(class,
                        "1" = "0",   # Not CKD
                        "2" = "1"))  # CKD
```

```{r}
ckd_clean$class <- factor(ckd_clean$class, levels = c("0", "1"))
```

```{r}
levels(ckd_clean$class)
table(ckd_clean$class)
prop.table(table(ckd_clean$class))
```

After applying these imputations, I confirmed that the dataset is complete by running `colSums(is.na(ckd_clean))`, which showed **zero missing values** across all 26 variables.

```{r}
# Model 1: Age, Blood Pressure, Serum Creatinine, Hemoglobin
logit1 <- glm(class ~ age + bp + sc + hemo,
              data = ckd_clean, family = "binomial")

summary(logit1)

# Odds ratios
exp(coef(logit1))
```

```{r}
# McFadden's pseudo-R2
pseudoR2 <- function(model) {
  1 - (model$deviance / model$null.deviance)
}

pseudoR2(logit1)  # for Model 1
```

```{r}
library(pROC)
```

```{r}
# Model 1: Predicted probabilities
prob1 <- predict(logit1, type = "response")
roc1 <- roc(ckd_clean$class, prob1)   # ROC curve
auc(roc1)                             # AUC value
plot(roc1, main = "ROC Curve - Logistic Model 1")
```

## **Logistic Model 1**

### Model fit

-   **Residual deviance = 122.86** (vs Null deviance = 528.22) → huge drop, model fits well.

-   **AIC = 132.86** → lower AIC indicates strong fit.

-   **McFadden’s pseudo-R² = 0.767** → excellent explanatory power (above 0.4 is usually very strong).

-   **ROC-AUC = 0.983** → outstanding classification accuracy (close to 1 = near-perfect).

This model used age, blood pressure, serum creatinine, and hemoglobin to predict CKD status. The results show that **serum creatinine** is the strongest predictor, with higher levels dramatically increasing the likelihood of CKD. **Hemoglobin** is also highly significant, where lower values are strongly associated with CKD. **Blood pressure** has a moderate but significant effect, with each unit increase raising the odds of CKD by about 6%. **Age** was not a significant factor in this dataset. Overall, the model fits extremely well, with a **pseudo-R² of 0.77** and an **ROC-AUC of 0.98**, indicating excellent classification accuracy.

```{r}
set.seed(1013)
idx      <- sample(nrow(ckd_clean), 0.8 * nrow(ckd_clean))
train.df <- ckd_clean[idx, ]
test.df  <- ckd_clean[-idx, ]
```

**Classification Tree – Model A (clinical labs)**

```{r}
treeA <- rpart(class ~ age + bp + sc + hemo,
               data = train.df, method = "class", cp = 0.003)
rpart.plot(treeA, digits = -2, extra = 101)
```

**Classification Tree – Model B (comorbid flags)**

```{r}
treeB <- rpart(class ~ htn + dm + cad + ane,
               data = train.df, method = "class", cp = 0.003)
rpart.plot(treeB, digits = -2)
```

**Regression Tree – Model C (predict hemoglobin)**

```{r}
treeC <- rpart(hemo ~ age + bp + htn + class,
               data = train.df, method = "anova", cp = 0.003)
rpart.plot(treeC, digits = -2, extra = 101)
```

```{r}
# Cross-validation plot
plotcp(treeA)
plotcp(treeB) 
```

```{r}
best_cp <- 0.14

treeA_pruned <- prune(treeA, cp = best_cp)

rpart.plot(treeA_pruned, digits = -2, extra = 101)
```

```{r}
table(train.df$class)
table(test.df$class)
```

```{r}
test.df$pred_treeA <- predict(treeA_pruned, newdata = test.df, type = "class")

confusionMatrix(test.df$pred_treeA, test.df$class, positive = "1")
```

```{r}
best_cp_B <- 0.11
treeB_pruned <- prune(treeB, cp = best_cp_B)

rpart.plot(treeB_pruned, digits = -2, extra = 101)
```

```{r}
test.df$pred_treeB <- predict(treeB_pruned, newdata = test.df, type = "class")

confusionMatrix(test.df$pred_treeB, test.df$class, positive = "1")
```

Overall, Tree A was selected as the best classification tree due to its higher accuracy, stronger generalization, and clinical interpretability, suggesting that laboratory measures such as serum creatinine and hemoglobin remain the most reliable indicators for CKD prediction.

```{r}
plotcp(treeC)
```

```{r}
best_cp_C <- 0.03

treeC_pruned <- prune(treeC, cp = best_cp_C)

rpart.plot(treeC_pruned, digits = -2, extra = 101)
```

```{r}
test.df$pred_treeC <- predict(treeC_pruned, newdata = test.df)

rmse <- function(actual, pred) sqrt(mean((actual - pred)^2))
mae  <- function(actual, pred) mean(abs(actual - pred))

rmse_val <- rmse(test.df$hemo, test.df$pred_treeC)
mae_val  <- mae(test.df$hemo, test.df$pred_treeC)

rmse_val
mae_val
```

Between the three trees, Tree A (Classification) provides the most reliable predictive performance. It achieves the highest accuracy (92.5%), strong sensitivity (0.91), and excellent balance between detecting CKD cases and avoiding false alarms. While the regression tree (Tree C) reasonably predicts hemoglobin, its RMSE ≈ 1.88 indicates moderate error. Therefore, Tree A is selected as the best model for its superior predictive accuracy and interpretability in identifying CKD patients.

### **Comparing Tree A and Logistic Regression Model 1**

Both models aimed to predict CKD status (1 = CKD, 0 = Not CKD) based on age, blood pressure, serum creatinine, and hemoglobin. The logistic regression model achieved a pseudo-R² of 0.77 and an AUC of 0.98, indicating excellent predictive power and strong model fit. Significant predictors included serum creatinine (p \< 0.001) and hemoglobin (p \< 0.001), confirming that higher creatinine and lower hemoglobin are key indicators of CKD. Blood pressure also showed a moderate effect, while age was not significant.

The classification tree (Tree A) used the same predictors but learned relationships through recursive partitioning rather than fixed coefficients. After pruning (cp ≈ 0.014), Tree A achieved 92.5 % accuracy, 90.7 % sensitivity, and 96.1 % specificity, with a Kappa of 0.84, reflecting excellent agreement between predicted and actual CKD status. The top splits in the tree also emphasized serum creatinine and hemoglobin, consistent with the logistic model’s findings.

Comparatively, both models performed very well; however, their strengths differ.

-   The logistic regression offers stronger overall discrimination (AUC = 0.98) and clearer interpretability through odds ratios and significance tests.

-   The classification tree provides greater interpretability for non-technical audiences, showing clear threshold values (e.g., “if serum creatinine \> X, then CKD = Yes”).

Given its slightly lower statistical fit but higher practical transparency, Tree A is selected as the final model for its balanced predictive accuracy, interpretability, and alignment with the logistic regression’s significant predictors.
